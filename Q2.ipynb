{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI8RgacrI9-E",
        "outputId": "63d813a0-d0b2-4adb-e0b4-954fcbd68ca6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q supervision\n",
        "!pip install -q git+https://github.com/facebookresearch/sam2.git\n",
        "!pip install -q git+https://github.com/IDEA-Research/GroundingDINO.git\n",
        "\n",
        "# Download model weights\n",
        "!mkdir -p checkpoints\n",
        "!wget -q -P checkpoints https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt\n",
        "!wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sam2.build_sam import build_sam2\n",
        "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
        "from groundingdino.util.inference import load_model, predict\n",
        "import supervision as sv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dvqX7SrJFJm",
        "outputId": "aef407e6-388c-4fb8-90b0-472cd3d6c23b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "UserWarning: Failed to load custom C++ ops. Running on CPU mode Only!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/IDEA-Research/GroundingDINO.git@main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11URzKmga495",
        "outputId": "210a37f9-870b-4609-d373-b9c98fc37a02"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/IDEA-Research/GroundingDINO.git@main\n",
            "  Cloning https://github.com/IDEA-Research/GroundingDINO.git (to revision main) to /tmp/pip-req-build-ml4p21en\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/IDEA-Research/GroundingDINO.git /tmp/pip-req-build-ml4p21en\n",
            "  Resolved https://github.com/IDEA-Research/GroundingDINO.git to commit 856dde20aee659246248e20734ef9ba5214f5e44\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from groundingdino==0.1.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from groundingdino==0.1.0) (0.23.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from groundingdino==0.1.0) (4.56.2)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.12/dist-packages (from groundingdino==0.1.0) (2.4.0)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.12/dist-packages (from groundingdino==0.1.0) (0.43.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (from groundingdino==0.1.0) (1.0.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from groundingdino==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from groundingdino==0.1.0) (4.12.0.88)\n",
            "Requirement already satisfied: supervision>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from groundingdino==0.1.0) (0.26.1)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.12/dist-packages (from groundingdino==0.1.0) (2.0.10)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from supervision>=0.22.0->groundingdino==0.1.0) (1.16.2)\n",
            "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.12/dist-packages (from supervision>=0.22.0->groundingdino==0.1.0) (3.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from supervision>=0.22.0->groundingdino==0.1.0) (6.0.3)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from supervision>=0.22.0->groundingdino==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.12/dist-packages (from supervision>=0.22.0->groundingdino==0.1.0) (11.3.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from supervision>=0.22.0->groundingdino==0.1.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.12/dist-packages (from supervision>=0.22.0->groundingdino==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm->groundingdino==0.1.0) (0.35.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm->groundingdino==0.1.0) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (3.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers->groundingdino==0.1.0) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->groundingdino==0.1.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->groundingdino==0.1.0) (0.22.1)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.12/dist-packages (from yapf->groundingdino==0.1.0) (4.4.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm->groundingdino==0.1.0) (1.1.10)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision>=0.22.0->groundingdino==0.1.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision>=0.22.0->groundingdino==0.1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision>=0.22.0->groundingdino==0.1.0) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision>=0.22.0->groundingdino==0.1.0) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision>=0.22.0->groundingdino==0.1.0) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision>=0.22.0->groundingdino==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision>=0.22.0->groundingdino==0.1.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision>=0.22.0->groundingdino==0.1.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision>=0.22.0->groundingdino==0.1.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision>=0.22.0->groundingdino==0.1.0) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->groundingdino==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->groundingdino==0.1.0) (3.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision>=0.22.0->groundingdino==0.1.0) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Load SAM 2\n",
        "sam2_checkpoint = \"checkpoints/sam2_hiera_large.pt\"\n",
        "model_cfg = \"sam2_hiera_l.yaml\"\n",
        "# Explicitly set device to 'cpu'\n",
        "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device='cpu')\n",
        "sam2_predictor = SAM2ImagePredictor(sam2_model)\n",
        "\n",
        "# Load GroundingDINO\n",
        "grounding_model = load_model(\n",
        "    \"groundingdino_swint_ogc.pth\",\n",
        "    \"GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\"\n",
        ")\n",
        "# Explicitly set device to 'cpu' for GroundingDINO model as well\n",
        "grounding_model.to('cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "C5RtPEw-JG77",
        "outputId": "a30ddcef-b409-4d8c-82c3-603b509ecb17"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Only py/yml/yaml/json type are supported now!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3739635177.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Load GroundingDINO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m grounding_model = load_model(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;34m\"groundingdino_swint_ogc.pth\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;34m\"GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/groundingdino/util/inference.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(model_config_path, model_checkpoint_path, device)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_checkpoint_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSLConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/groundingdino/util/slconfig.py\u001b[0m in \u001b[0;36mfromfile\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mcfg_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSLConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file2dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mSLConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/groundingdino/util/slconfig.py\u001b[0m in \u001b[0;36m_file2dict\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mcfg_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Only py/yml/yaml/json type are supported now!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mcfg_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Only py/yml/yaml/json type are supported now!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_image_with_text(image_path, text_prompt, box_threshold=0.35, text_threshold=0.25):\n",
        "    \"\"\"\n",
        "    Segments an object in an image based on text prompt\n",
        "\n",
        "    Args:\n",
        "        image_path: Path to image file\n",
        "        text_prompt: Text description of object (e.g., \"cat\", \"person\")\n",
        "        box_threshold: Confidence threshold for detection\n",
        "        text_threshold: Text matching threshold\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Load image\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image_np = np.array(image)\n",
        "\n",
        "    # 2. Use GroundingDINO to detect object from text\n",
        "    boxes, logits, phrases = predict(\n",
        "        model=grounding_model,\n",
        "        image=image,\n",
        "        caption=text_prompt,\n",
        "        box_threshold=box_threshold,\n",
        "        text_threshold=text_threshold\n",
        "    )\n",
        "\n",
        "    # 3. Convert boxes to SAM 2 format\n",
        "    h, w = image_np.shape[:2]\n",
        "    boxes_xyxy = boxes * torch.Tensor([w, h, w, h])\n",
        "    input_boxes = boxes_xyxy.cpu().numpy()\n",
        "\n",
        "    # 4. Use SAM 2 to generate precise masks\n",
        "    sam2_predictor.set_image(image_np)\n",
        "    masks, scores, _ = sam2_predictor.predict(\n",
        "        point_coords=None,\n",
        "        point_labels=None,\n",
        "        box=input_boxes,\n",
        "        multimask_output=False\n",
        "    )\n",
        "\n",
        "    # 5. Visualize results\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # Original image\n",
        "    axes[0].imshow(image_np)\n",
        "    axes[0].set_title(\"Original Image\")\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Detection boxes\n",
        "    axes[1].imshow(image_np)\n",
        "    for box in input_boxes:\n",
        "        x1, y1, x2, y2 = box\n",
        "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
        "                            fill=False, color='red', linewidth=2)\n",
        "        axes[1].add_patch(rect)\n",
        "    axes[1].set_title(f\"Detected: '{text_prompt}'\")\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    # Segmentation mask overlay\n",
        "    axes[2].imshow(image_np)\n",
        "    if len(masks) > 0:\n",
        "        mask = masks[0]\n",
        "        colored_mask = np.zeros_like(image_np)\n",
        "        colored_mask[mask] = [0, 255, 0]  # Green mask\n",
        "        axes[2].imshow(colored_mask, alpha=0.5)\n",
        "    axes[2].set_title(\"Segmentation Mask\")\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return masks, boxes, phrases"
      ],
      "metadata": {
        "id": "Z2fx4iTwJJpZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload or use a sample image\n",
        "from google.colab import files\n",
        "\n",
        "# # Option 1: Upload your own image\n",
        "# uploaded = files.upload()\n",
        "# image_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Option 2: Or download a sample\n",
        "!wget -O sample.jpg \"https://images.unsplash.com/photo-1514888286974-6c03e2ca1dba\"\n",
        "image_path = \"sample.jpg\"\n",
        "\n",
        "# Run segmentation\n",
        "text_prompt = \"cat\"  # Change this to segment different objects\n",
        "masks, boxes, phrases = segment_image_with_text(image_path, text_prompt)\n",
        "\n",
        "print(f\"Found {len(masks)} object(s) matching '{text_prompt}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "rzdYKWDPJK4h",
        "outputId": "a248aefb-7fae-4917-ff07-fe3e8cbd2229"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-04 09:07:36--  https://images.unsplash.com/photo-1514888286974-6c03e2ca1dba\n",
            "Resolving images.unsplash.com (images.unsplash.com)... 151.101.2.208, 151.101.66.208, 151.101.130.208, ...\n",
            "Connecting to images.unsplash.com (images.unsplash.com)|151.101.2.208|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2017802 (1.9M) [image/jpeg]\n",
            "Saving to: ‘sample.jpg’\n",
            "\n",
            "\rsample.jpg            0%[                    ]       0  --.-KB/s               \rsample.jpg          100%[===================>]   1.92M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-10-04 09:07:36 (32.5 MB/s) - ‘sample.jpg’ saved [2017802/2017802]\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'grounding_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-466112386.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Run segmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtext_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cat\"\u001b[0m  \u001b[0;31m# Change this to segment different objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphrases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment_image_with_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Found {len(masks)} object(s) matching '{text_prompt}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3017915012.py\u001b[0m in \u001b[0;36msegment_image_with_text\u001b[0;34m(image_path, text_prompt, box_threshold, text_threshold)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# 2. Use GroundingDINO to detect object from text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     boxes, logits, phrases = predict(\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrounding_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mcaption\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'grounding_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test different objects\n",
        "test_prompts = [\"person\", \"car\", \"dog\", \"tree\", \"building\"]\n",
        "\n",
        "for prompt in test_prompts:\n",
        "    print(f\"\\nSearching for: {prompt}\")\n",
        "    try:\n",
        "        masks, _, _ = segment_image_with_text(image_path, prompt)\n",
        "        print(f\"Success! Found {len(masks)} instance(s)\")\n",
        "    except:\n",
        "        print(f\"No {prompt} found in image\")"
      ],
      "metadata": {
        "id": "d1F4j-bYJQZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install video processing\n",
        "!pip install -q opencv-python-headless\n",
        "\n",
        "def segment_video_with_text(video_path, text_prompt, output_path=\"output.mp4\"):\n",
        "    \"\"\"\n",
        "    Segments object across video frames using SAM 2 tracking\n",
        "    \"\"\"\n",
        "    import cv2\n",
        "    from sam2.build_sam import build_sam2_video_predictor\n",
        "\n",
        "    # Initialize video predictor\n",
        "    video_predictor = build_sam2_video_predictor(model_cfg, sam2_checkpoint)\n",
        "\n",
        "    # Process video frame by frame\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Video writer\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Get first frame detection\n",
        "    ret, first_frame = cap.read()\n",
        "    # ... (detect object with GroundingDINO in first frame)\n",
        "    # ... (propagate mask through video with SAM 2)\n",
        "\n",
        "    print(f\"Video segmentation complete: {output_path}\")"
      ],
      "metadata": {
        "id": "p6y0RhfOJdp3"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}